{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Quick Start: Creating Sample-wise Unlearnable Examples</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from Get_data import get_data\n",
    "from Make_label import make_label\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# # Prepare Dataset---------------------------------------------------------------------------------------\n",
    "# train_transform = [\n",
    "#     transforms.ToTensor()\n",
    "# ]\n",
    "# test_transform = [\n",
    "#     transforms.ToTensor()\n",
    "# ]\n",
    "# train_transform = transforms.Compose(train_transform)\n",
    "# test_transform = transforms.Compose(test_transform)\n",
    "\n",
    "# clean_train_dataset = datasets.CIFAR10(root='../datasets', train=True, download=True, transform=train_transform)\n",
    "# clean_test_dataset = datasets.CIFAR10(root='../datasets', train=False, download=True, transform=test_transform)\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "# clean_train_loader = DataLoader(dataset=clean_train_dataset, batch_size=512,\n",
    "#                                 shuffle=False, pin_memory=True,\n",
    "#                                 drop_last=False, num_workers=12)\n",
    "# clean_test_loader = DataLoader(dataset=clean_test_dataset, batch_size=512,\n",
    "#                                 shuffle=False, pin_memory=True,\n",
    "#                                 drop_last=False, num_workers=12)\n",
    "#--------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#   插入我们自己的dataset\n",
    "# 获取数据\n",
    "start_num = 0\n",
    "end_num = 70000 #   start_num 到 7W作为训练集 ，剩余是验证集\n",
    "target = 9                                              # 先试第9个字节\n",
    "file_addr = 'E:\\\\HZY\\\\matlab\\\\preprocess\\\\R_10W_halfbyte32.mat'  # 数据位置\n",
    "# file_addr = 'C:/Users/Administrator/Desktop/并行测试/R_99000_train.mat'  # 数据位置\n",
    "X, plaintext, key, cipher = get_data(file_addr)\n",
    "label = make_label(plaintext, key, target)\n",
    "X = torch.FloatTensor(X)  # 数据类型转换\n",
    "X=X.view(-1,1,2940,1)   #   重塑X为[batchsize,1,2940,1]的形状\n",
    "label = torch.LongTensor(label)  # 数据类型转换\n",
    "db_train = TensorDataset(X[start_num:end_num], label[start_num:end_num])  # 封装数据集\n",
    "#train_DataLoader = DataLoader(db_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "db_val = TensorDataset(X[end_num:99000], label[end_num:99000])\n",
    "#val_DataLoader = DataLoader(db_val, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "#dataloader = {'train': train_DataLoader, 'val':val_DataLoader}\n",
    "\n",
    "clean_train_loader = DataLoader(dataset=db_train, batch_size=64,\n",
    "                                shuffle=False, pin_memory=True,\n",
    "                                drop_last=False, num_workers=12)\n",
    "clean_test_loader = DataLoader(dataset=db_val, batch_size=64,\n",
    "                                shuffle=False, pin_memory=True,\n",
    "                                drop_last=False, num_workers=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\UE\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from models.ResNet import ResNet18\n",
    "import toolbox\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "base_model = ResNet18()\n",
    "base_model = base_model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=base_model.parameters(), lr=0.1, weight_decay=0.0005, momentum=0.9)\n",
    "\n",
    "noise_generator = toolbox.PerturbationTool(epsilon=0.03137254901960784, num_steps=20, step_size=0.0031372549019607846)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Generate Error-Minimizing Noise</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:05<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 8.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:06<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 11.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:07<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 31.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:07<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 67.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:08<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 88.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:07<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 68.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:07<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 53.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:08<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 96.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:07<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 97.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98/98 [03:07<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 99.72\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "noise = torch.zeros([50000, 3, 32, 32])\n",
    "data_iter = iter(clean_train_loader)\n",
    "condition = True\n",
    "train_idx = 0\n",
    "\n",
    "while condition:\n",
    "    # optimize theta for M steps\n",
    "    base_model.train()\n",
    "    for param in base_model.parameters():\n",
    "        param.requires_grad = True\n",
    "    for j in range(0, 10):\n",
    "        try:\n",
    "            (images, labels) = next(data_iter)\n",
    "        except:\n",
    "            train_idx = 0\n",
    "            data_iter = iter(clean_train_loader)\n",
    "            (images, labels) = next(data_iter)\n",
    "        \n",
    "        for i, _ in enumerate(images):\n",
    "            # Update noise to images\n",
    "            images[i] += noise[train_idx]\n",
    "            train_idx += 1\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        base_model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        logits = base_model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(base_model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Perturbation over entire dataset\n",
    "    idx = 0\n",
    "    for param in base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for i, (images, labels) in tqdm(enumerate(clean_train_loader), total=len(clean_train_loader)):\n",
    "        batch_start_idx, batch_noise = idx, []\n",
    "        for i, _ in enumerate(images):\n",
    "            # Update noise to images\n",
    "            batch_noise.append(noise[idx])\n",
    "            idx += 1\n",
    "        batch_noise = torch.stack(batch_noise).cuda()\n",
    "        \n",
    "        # Update sample-wise perturbation\n",
    "        base_model.eval()\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        perturb_img, eta = noise_generator.min_min_attack(images, labels, base_model, optimizer, criterion, \n",
    "                                                          random_noise=batch_noise)\n",
    "        for i, delta in enumerate(eta):\n",
    "            noise[batch_start_idx+i] = delta.clone().detach().cpu()\n",
    "        \n",
    "    # Eval stop condition\n",
    "    eval_idx, total, correct = 0, 0, 0\n",
    "    for i, (images, labels) in enumerate(clean_train_loader):\n",
    "        for i, _ in enumerate(images):\n",
    "            # Update noise to images\n",
    "            images[i] += noise[eval_idx]\n",
    "            eval_idx += 1\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        with torch.no_grad():\n",
    "            logits = base_model(images)\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = correct / total\n",
    "    print('Accuracy %.2f' % (acc*100))\n",
    "    if acc > 0.99:\n",
    "        condition=False      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 2.5098e-02,  3.1373e-02,  2.8235e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [-9.4118e-03,  1.8824e-02, -1.2549e-02,  ..., -2.8235e-02,\n",
      "           -2.8235e-02, -2.8235e-02],\n",
      "          [-2.1961e-02, -3.1373e-02, -3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          ...,\n",
      "          [ 3.1370e-03, -2.1961e-02, -2.8235e-02,  ...,  6.2747e-03,\n",
      "            1.2549e-02,  2.5098e-02],\n",
      "          [-3.1370e-03,  9.4119e-03,  9.4119e-03,  ...,  2.3842e-07,\n",
      "           -2.5098e-02, -3.1373e-02],\n",
      "          [-3.1370e-03,  3.1375e-03, -1.5686e-02,  ..., -6.2742e-03,\n",
      "           -2.3842e-07, -1.5686e-02]],\n",
      "\n",
      "         [[-3.1373e-02, -5.9605e-08, -2.8235e-02,  ...,  3.1371e-03,\n",
      "           -1.5686e-02, -2.1961e-02],\n",
      "          [-3.1373e-02,  1.2549e-02,  6.2745e-03,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [ 3.1373e-02,  2.5098e-02,  2.5098e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          ...,\n",
      "          [-3.1373e-02,  1.8823e-02,  9.4115e-03,  ..., -1.8824e-02,\n",
      "            9.4117e-03,  2.1961e-02],\n",
      "          [ 3.1370e-03, -6.2745e-03, -9.4119e-03,  ...,  3.1373e-02,\n",
      "            2.5098e-02,  2.8235e-02],\n",
      "          [ 1.2549e-02,  2.1961e-02,  1.5686e-02,  ...,  1.2549e-02,\n",
      "            2.5098e-02,  3.1373e-02]],\n",
      "\n",
      "         [[ 3.1373e-02, -2.5098e-02, -2.5098e-02,  ..., -2.8235e-02,\n",
      "           -2.8235e-02, -2.8235e-02],\n",
      "          [ 3.1373e-02,  0.0000e+00,  1.2549e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-1.8823e-02,  0.0000e+00, -3.1373e-02,  ..., -1.8824e-02,\n",
      "           -1.8824e-02,  2.8235e-02],\n",
      "          ...,\n",
      "          [-2.1961e-02, -2.8235e-02, -2.5098e-02,  ..., -3.1373e-02,\n",
      "           -2.7451e-02, -2.8235e-02],\n",
      "          [ 3.1373e-02,  3.1372e-03,  3.1373e-02,  ..., -3.1373e-02,\n",
      "           -1.2549e-02, -1.8824e-02],\n",
      "          [ 9.4117e-03,  1.5686e-02, -2.8235e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  2.5098e-02],\n",
      "          ...,\n",
      "          [-2.3842e-07,  6.2742e-03, -1.8824e-02,  ..., -2.5098e-02,\n",
      "           -2.5098e-02, -2.5098e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -2.8235e-02,\n",
      "           -2.8235e-02, -2.8235e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -2.8235e-02,\n",
      "           -2.8235e-02, -2.8235e-02]],\n",
      "\n",
      "         [[ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [-1.2549e-02, -3.1373e-02,  1.8824e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          ...,\n",
      "          [ 1.2549e-02,  6.2747e-03,  2.5098e-02,  ...,  2.5098e-02,\n",
      "            1.2549e-02,  3.1373e-02],\n",
      "          [ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ...,  2.8235e-02,\n",
      "            2.8235e-02,  2.8235e-02],\n",
      "          [ 2.8235e-02,  3.1373e-02,  3.1373e-02,  ...,  2.8235e-02,\n",
      "            2.8235e-02,  2.8235e-02]],\n",
      "\n",
      "         [[-2.1960e-02, -3.1373e-02, -3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-3.1373e-02, -1.2549e-02, -3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [-1.8824e-02,  2.5098e-02,  1.8824e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          ...,\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -2.8235e-02,\n",
      "           -2.8235e-02, -2.8235e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -2.8235e-02,\n",
      "           -2.8235e-02, -2.8235e-02],\n",
      "          [ 1.2549e-02,  6.2746e-03, -3.1373e-02,  ..., -2.8235e-02,\n",
      "           -3.1373e-02, -3.1373e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -3.1373e-02,\n",
      "            1.0980e-02,  1.0980e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ...,  3.1372e-03,\n",
      "            3.1372e-03,  3.1372e-03],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ...,  7.0588e-03,\n",
      "            7.0588e-03,  7.0588e-03],\n",
      "          ...,\n",
      "          [ 5.9605e-08, -6.2745e-03, -1.2549e-02,  ..., -1.2549e-02,\n",
      "           -2.5098e-02, -6.2745e-03],\n",
      "          [-2.5098e-02, -1.8824e-02,  6.2746e-03,  ...,  1.2549e-02,\n",
      "            1.2549e-02,  6.2746e-03],\n",
      "          [-1.2549e-02, -1.8824e-02,  3.1373e-02,  ...,  5.9605e-08,\n",
      "            5.9605e-08, -6.2745e-03]],\n",
      "\n",
      "         [[ 3.1372e-03,  1.0980e-02,  1.0980e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [ 3.1372e-03,  3.1372e-03,  3.1372e-03,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-2.5098e-02, -1.4902e-02,  7.0588e-03,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          ...,\n",
      "          [ 6.2745e-03,  1.2549e-02,  1.2549e-02,  ..., -6.2746e-03,\n",
      "           -6.2746e-03, -5.9605e-08],\n",
      "          [ 1.8824e-02,  2.5098e-02, -5.9605e-08,  ..., -1.2549e-02,\n",
      "            1.2549e-02,  2.5098e-02],\n",
      "          [-6.2746e-03,  3.1373e-02, -3.1373e-02,  ..., -5.9605e-08,\n",
      "           -6.2746e-03,  2.8235e-02]],\n",
      "\n",
      "         [[-3.1373e-02, -3.1373e-02, -3.1373e-02,  ...,  1.0980e-02,\n",
      "            1.0980e-02,  1.0980e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ...,  3.1372e-03,\n",
      "            3.1372e-03,  3.1372e-03],\n",
      "          [-6.2747e-03, -3.1373e-02, -3.1373e-02,  ...,  7.0588e-03,\n",
      "            7.0588e-03,  7.0588e-03],\n",
      "          ...,\n",
      "          [-6.2745e-03, -6.2745e-03, -6.2745e-03,  ..., -2.8235e-02,\n",
      "           -2.8235e-02, -2.5098e-02],\n",
      "          [ 1.2549e-02,  1.8824e-02,  1.2549e-02,  ..., -2.1961e-02,\n",
      "           -2.5098e-02, -2.8235e-02],\n",
      "          [-2.5098e-02, -3.1373e-02, -1.8824e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -1.8824e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.2745e-03,  1.2549e-02, -3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [-4.4703e-08, -2.8235e-02, -3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [-2.5098e-02, -2.5098e-02, -2.5098e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          ...,\n",
      "          [ 1.2549e-02,  6.2746e-03, -6.2745e-03,  ..., -6.2745e-03,\n",
      "           -6.2745e-03, -6.2745e-03],\n",
      "          [-6.2745e-03, -6.2745e-03,  5.9605e-08,  ..., -2.2352e-08,\n",
      "           -1.4901e-08, -2.3529e-03],\n",
      "          [-3.1373e-02, -3.1373e-02, -1.8824e-02,  ..., -2.5098e-02,\n",
      "           -2.5098e-02, -2.5098e-02]],\n",
      "\n",
      "         [[-1.2549e-02,  1.8823e-02,  3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [ 1.2549e-02,  1.2549e-02, -6.2742e-03,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          ...,\n",
      "          [-1.8824e-02,  6.2745e-03,  6.2745e-03,  ...,  6.2745e-03,\n",
      "            6.2745e-03,  6.2745e-03],\n",
      "          [-5.9605e-08, -5.9605e-08, -5.9605e-08,  ..., -5.9605e-08,\n",
      "            6.2745e-03,  1.2549e-02],\n",
      "          [ 3.1373e-02,  2.1961e-02,  1.2549e-02,  ...,  2.5098e-02,\n",
      "            2.5098e-02,  2.5098e-02]],\n",
      "\n",
      "         [[ 1.2549e-02, -3.1373e-02, -3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [ 3.1373e-02, -3.1375e-03,  3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [ 3.1373e-02,  1.4902e-02,  3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          ...,\n",
      "          [-6.2745e-03, -6.2745e-03, -6.2745e-03,  ..., -2.5098e-02,\n",
      "           -2.8235e-02, -2.5098e-02],\n",
      "          [ 5.9605e-08, -1.5686e-02, -1.2549e-02,  ..., -2.8235e-02,\n",
      "           -2.5098e-02, -6.2746e-03],\n",
      "          [-1.8824e-02, -2.8235e-02, -2.8235e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          ...,\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ...,  3.1370e-03,\n",
      "           -2.3842e-07, -2.3842e-07],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -1.8824e-02,\n",
      "           -1.8824e-02, -1.8824e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -1.8824e-02,\n",
      "           -1.8824e-02, -1.8824e-02]],\n",
      "\n",
      "         [[-3.1373e-02, -3.1373e-02, -3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          [ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  3.1373e-02],\n",
      "          ...,\n",
      "          [ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ...,  9.4119e-03,\n",
      "           -9.4115e-03,  1.2549e-02],\n",
      "          [ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ...,  1.8824e-02,\n",
      "            1.8824e-02,  1.8824e-02],\n",
      "          [ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ...,  1.8824e-02,\n",
      "            1.8824e-02,  1.8824e-02]],\n",
      "\n",
      "         [[ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [ 3.1372e-02, -3.1373e-02,  3.1372e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          ...,\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -1.8824e-02,\n",
      "           -1.8824e-02,  2.8235e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -1.8824e-02,\n",
      "           -1.8824e-02, -1.8824e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -3.1373e-02,  ..., -1.8824e-02,\n",
      "           -1.8824e-02, -1.8824e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ..., -2.5098e-02,\n",
      "           -2.5098e-02, -3.1373e-02],\n",
      "          [ 3.1373e-02,  3.1373e-02,  2.8235e-02,  ..., -2.5098e-02,\n",
      "           -2.5098e-02, -2.5098e-02],\n",
      "          [ 3.1372e-02,  1.8823e-02, -3.1373e-02,  ..., -2.5098e-02,\n",
      "           -2.5098e-02, -2.5098e-02],\n",
      "          ...,\n",
      "          [-2.5098e-02, -2.5098e-02, -2.5098e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-2.5098e-02, -2.5098e-02, -2.5098e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1372e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -2.5098e-02,  ...,  2.8235e-02,\n",
      "            2.8235e-02,  2.8235e-02]],\n",
      "\n",
      "         [[-3.1373e-02, -3.1373e-02, -2.8235e-02,  ...,  2.5098e-02,\n",
      "            2.5098e-02,  3.1373e-02],\n",
      "          [-3.1373e-02, -3.1373e-02, -2.3842e-07,  ...,  2.5098e-02,\n",
      "            2.5098e-02,  3.1373e-02],\n",
      "          [-6.2742e-03,  2.5098e-02,  3.1373e-02,  ...,  2.5098e-02,\n",
      "            2.5098e-02,  2.5098e-02],\n",
      "          ...,\n",
      "          [ 2.5098e-02,  2.5098e-02,  2.5098e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  2.8235e-02],\n",
      "          [ 2.5098e-02,  2.5098e-02,  2.5098e-02,  ...,  3.1373e-02,\n",
      "            3.1373e-02,  2.8235e-02],\n",
      "          [ 3.1373e-02,  3.1373e-02,  3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02]],\n",
      "\n",
      "         [[ 1.8823e-02,  2.8235e-02,  6.2742e-03,  ..., -2.5098e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-1.2549e-02, -3.1373e-02, -3.1373e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-2.5098e-02, -2.5098e-02, -2.5098e-02,  ..., -2.5098e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          ...,\n",
      "          [-2.5098e-02, -2.5098e-02, -2.5098e-02,  ..., -2.8235e-02,\n",
      "           -2.8235e-02, -2.8235e-02],\n",
      "          [-2.5098e-02, -2.5098e-02, -2.5098e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02],\n",
      "          [-3.1373e-02, -2.5098e-02, -2.5098e-02,  ..., -3.1373e-02,\n",
      "           -3.1373e-02, -3.1373e-02]]]])\n"
     ]
    }
   ],
   "source": [
    "# Examine the noise\n",
    "print(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Creat Unlearnable Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Add standard augmentation\n",
    "train_transform = [\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "]\n",
    "train_transform = transforms.Compose(train_transform)\n",
    "clean_train_dataset = datasets.CIFAR10(root='../datasets', train=True, download=True, transform=train_transform)\n",
    "unlearnable_train_dataset = datasets.CIFAR10(root='../datasets', train=True, download=True, transform=train_transform)\n",
    "\n",
    "perturb_noise = noise.mul(255).clamp_(0, 255).permute(0, 2, 3, 1).to('cpu').numpy()\n",
    "unlearnable_train_dataset.data = unlearnable_train_dataset.data.astype(np.float32)\n",
    "for i in range(len(unlearnable_train_dataset)):\n",
    "    unlearnable_train_dataset.data[i] += perturb_noise[i]\n",
    "    unlearnable_train_dataset.data[i] = np.clip(unlearnable_train_dataset.data[i], a_min=0, a_max=255)\n",
    "unlearnable_train_dataset.data = unlearnable_train_dataset.data.astype(np.uint8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Visualize Clean Images, Error-Minimizing Noise, Unlearnable Images</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "def imshow(img):\n",
    "    fig = plt.figure(figsize=(8, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "def get_pairs_of_imgs(idx):\n",
    "    clean_img = clean_train_dataset.data[idx]\n",
    "    unlearnable_img = unlearnable_train_dataset.data[idx]\n",
    "    clean_img = torchvision.transforms.functional.to_tensor(clean_img)\n",
    "    unlearnable_img = torchvision.transforms.functional.to_tensor(unlearnable_img)\n",
    "\n",
    "    x = noise[idx]\n",
    "    x_min = torch.min(x)\n",
    "    x_max = torch.max(x)\n",
    "    noise_norm = (x - x_min) / (x_max - x_min)\n",
    "    noise_norm = torch.clamp(noise_norm, 0, 1)\n",
    "    return [clean_img, noise_norm, unlearnable_img]\n",
    "    \n",
    "selected_idx = [random.randint(0, 50000) for _ in range(3)]\n",
    "img_grid = []\n",
    "for idx in selected_idx:\n",
    "    img_grid += get_pairs_of_imgs(idx)\n",
    "    \n",
    "\n",
    "imshow(torchvision.utils.make_grid(torch.stack(img_grid), nrow=3, pad_value=255))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train ResNet18 on Clean Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 39.76 Loss: 1.66: 100%|██████████| 391/391 [01:04<00:00,  6.08it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 3, 3], expected input[64, 1, 2940, 1] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 42\u001b[0m\n\u001b[0;32m     40\u001b[0m images, labels \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mcuda(), labels\u001b[39m.\u001b[39mcuda()\n\u001b[0;32m     41\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m---> 42\u001b[0m     logits \u001b[39m=\u001b[39m model(images)\n\u001b[0;32m     43\u001b[0m     _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(logits\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[0;32m     44\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\UE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\UE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\HZY\\Unlearnable-Examples\\models\\ResNet.py:81\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 81\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[0;32m     82\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(out)\n\u001b[0;32m     83\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(out)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\UE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\UE\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\UE\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\UE\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 3, 3], expected input[64, 1, 2940, 1] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "from util import AverageMeter\n",
    "from tqdm import tqdm   #   显示进度条\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1, weight_decay=0.0005, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=0)\n",
    "\n",
    "clean_loader = DataLoader(dataset=clean_train_dataset, batch_size=128,\n",
    "                                shuffle=True, pin_memory=True,\n",
    "                                drop_last=False, num_workers=12)\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "    # Train\n",
    "    model.train()\n",
    "    acc_meter = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "    pbar = tqdm(clean_loader, total=len(clean_loader))  # pbar，可迭代对象，引入包是为了显示进度条。同时也作为输入\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        acc = (predicted == labels).sum().item()/labels.size(0)\n",
    "        acc_meter.update(acc)\n",
    "        loss_meter.update(loss.item())\n",
    "        pbar.set_description(\"Acc %.2f Loss: %.2f\" % (acc_meter.avg*100, loss_meter.avg))\n",
    "    scheduler.step()\n",
    "    # Eval\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for i, (images, labels) in enumerate(clean_test_loader):\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = correct / total\n",
    "    tqdm.write('Clean Accuracy %.2f\\n' % (acc*100))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train ResNet18 on Unlearnable Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 36.99 Loss: 1.73: 100%|██████████| 391/391 [00:20<00:00, 19.17it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 35.16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 76.95 Loss: 0.65: 100%|██████████| 391/391 [00:20<00:00, 19.51it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 22.21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 93.06 Loss: 0.21: 100%|██████████| 391/391 [00:20<00:00, 19.51it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 23.69\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 95.13 Loss: 0.15: 100%|██████████| 391/391 [00:20<00:00, 19.37it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 25.79\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 96.16 Loss: 0.12: 100%|██████████| 391/391 [00:20<00:00, 19.23it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 20.87\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 96.78 Loss: 0.10: 100%|██████████| 391/391 [00:19<00:00, 19.56it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 19.92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 96.89 Loss: 0.10: 100%|██████████| 391/391 [00:19<00:00, 19.65it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 19.44\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 97.22 Loss: 0.08: 100%|██████████| 391/391 [00:20<00:00, 19.45it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 19.08\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 97.35 Loss: 0.08: 100%|██████████| 391/391 [00:20<00:00, 19.47it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 22.07\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 97.58 Loss: 0.07: 100%|██████████| 391/391 [00:20<00:00, 19.37it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 17.37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 97.89 Loss: 0.07: 100%|██████████| 391/391 [00:20<00:00, 19.43it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 20.82\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 97.85 Loss: 0.07: 100%|██████████| 391/391 [00:19<00:00, 19.56it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 18.45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 98.05 Loss: 0.06: 100%|██████████| 391/391 [00:19<00:00, 19.59it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 19.74\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 98.18 Loss: 0.06: 100%|██████████| 391/391 [00:20<00:00, 19.30it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 19.36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 98.30 Loss: 0.05: 100%|██████████| 391/391 [00:19<00:00, 19.55it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 22.84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 98.53 Loss: 0.05: 100%|██████████| 391/391 [00:20<00:00, 19.44it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 22.93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 98.61 Loss: 0.04: 100%|██████████| 391/391 [00:20<00:00, 19.52it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 16.04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.00 Loss: 0.03: 100%|██████████| 391/391 [00:20<00:00, 19.43it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 17.80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.08 Loss: 0.03: 100%|██████████| 391/391 [00:20<00:00, 19.33it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 22.51\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.22 Loss: 0.02: 100%|██████████| 391/391 [00:20<00:00, 19.32it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 23.77\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.44 Loss: 0.02: 100%|██████████| 391/391 [00:20<00:00, 19.22it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 23.28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.57 Loss: 0.02: 100%|██████████| 391/391 [00:20<00:00, 19.13it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 19.66\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.60 Loss: 0.01: 100%|██████████| 391/391 [00:19<00:00, 19.64it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 25.13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.76 Loss: 0.01: 100%|██████████| 391/391 [00:20<00:00, 19.43it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 23.19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.83 Loss: 0.01: 100%|██████████| 391/391 [00:19<00:00, 19.55it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 22.05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.89 Loss: 0.01: 100%|██████████| 391/391 [00:19<00:00, 19.56it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 22.94\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.88 Loss: 0.00: 100%|██████████| 391/391 [00:20<00:00, 19.42it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 23.66\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.94 Loss: 0.00: 100%|██████████| 391/391 [00:20<00:00, 19.44it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 23.19\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.95 Loss: 0.00: 100%|██████████| 391/391 [00:20<00:00, 19.53it/s]\n",
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 22.83\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc 99.94 Loss: 0.00: 100%|██████████| 391/391 [00:20<00:00, 19.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Accuracy 23.60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from util import AverageMeter\n",
    "\n",
    "model = ResNet18()\n",
    "model = model.cuda()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.1, weight_decay=0.0005, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30, eta_min=0)\n",
    "\n",
    "unlearnable_loader = DataLoader(dataset=unlearnable_train_dataset, batch_size=128,\n",
    "                                shuffle=True, pin_memory=True,\n",
    "                                drop_last=False, num_workers=12)\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "    # Train\n",
    "    model.train()\n",
    "    acc_meter = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "    pbar = tqdm(unlearnable_loader, total=len(unlearnable_loader))\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        acc = (predicted == labels).sum().item()/labels.size(0)\n",
    "        acc_meter.update(acc)\n",
    "        loss_meter.update(loss.item())\n",
    "        pbar.set_description(\"Acc %.2f Loss: %.2f\" % (acc_meter.avg*100, loss_meter.avg))\n",
    "    scheduler.step()\n",
    "    # Eval\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for i, (images, labels) in enumerate(clean_test_loader):\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        with torch.no_grad():\n",
    "            logits = model(images)\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    acc = correct / total\n",
    "    tqdm.write('Clean Accuracy %.2f\\n' % (acc*100))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
